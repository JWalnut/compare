"""
=====
Wordmap
=====
"""

# John Walnut
# v 0.2
# Class to hold all of our mapping methods
# 7/24/16

import progressbar
import networkx as nx
from document import Document
from nltk.corpus import wordnet as wn
import numpy as np
from os import listdir
import matplotlib.pyplot as plt

"""py:class::WordMap"""
class WordMap:

    @staticmethod
    def synonymList(word): #Helper method to generate a list of synonyms using Princeton's WordNet
        list = []
        setList = wn.synsets(word)
        for set in setList:
            for lem in set.lemma_names():
                list.append(str(lem))
        return list

    #Generates a map of synonyms from the set of words in document "doc"
    #Duplicate matches are ignored
    #Optional progress bar for map generation (default is on).  Quiet option turns off
    @staticmethod
    def generateWordMap(doc, quiet=False):
        i = 0
        map = nx.Graph()
        docSet = set(doc.wordlist)
        if not quiet:
            bar = progressbar.ProgressBar(max_value = len(docSet))
        for word in docSet:
            map.add_edge(word, word)
            synonyms = WordMap.synonymList(word)
            for syn in synonyms:
                if syn in docSet and not map.has_edge(word, syn):
                    map.add_edge(word, syn)
            i += 1
            if not quiet:
                bar.update(i)            
        return map

    #Generates a markov matrix from the word map generated in the method above
    @staticmethod
    def generateMarkov(theMap):
        adj = np.asarray(nx.adjacency_matrix(theMap).todense())
        adj = (adj + adj.transpose())/2
        N = len(theMap)
        arrayOfOnes = np.ones([N,1])
        rowSums = adj.dot(arrayOfOnes)
        diagonal = np.diag(rowSums.transpose()[0])
        markov = np.linalg.inv(diagonal).dot(adj)
        return markov

    #Generates a vertical vector of the frequency of occurrance in allWords of each word in document
    #If parameter "count" is true, the vector contains the actual frequence (i.e., if "test" appears three times, its entry will be "3")
    #If parameter "count" is false, the vector ignores duplicate occurances (i.e., "test"'s entry would be "1")
    #The order of the words appearing in the returned vector will match the order of the words appearing in allWords.wordlist
    @staticmethod
    def generateDocumentVector(allWords, document, count=False):
        totalWords = list(set(allWords.wordlist))
        docWords = []
        if count == True:
            docWords = document.wordlist
        else:
            docWords = list(set(document.wordlist))
        vector = np.zeros([len(totalWords),1])
        for i in range(len(totalWords)):
            if docWords.count(totalWords[i]) != -1:
                vector[i][0] = docWords.count(totalWords[i])
        return vector

    #Compares two documents using wordmap. Returns similarity measure
    #Depth determines how many times the document vectors are multiplied by the markov matrix (0 = once)
    #Quiet determines whether wordmap generation should show progress bar
    #Count determines whether word vectors should count words, or indicate presence alone
    @staticmethod
    def compareDocs(doc1, doc2, depth=0, quiet=False, count=False):
        markovDoc = Document(body=doc1.body+" "+doc2.body)
        markovMap = WordMap.generateWordMap(markovDoc, quiet)
        markov = WordMap.generateMarkov(markovMap)
        doc1vec = WordMap.generateDocumentVector(markovDoc, doc1, count)
        doc2vec = WordMap.generateDocumentVector(markovDoc, doc2, count)
        doc1vec /= np.sum(doc1vec)
        doc2vec /= np.sum(doc2vec)
        S1 = markov.dot(doc1vec)
        S2 = markov.dot(doc2vec)
        for i in range(int(depth)):
            S1 = markov.dot(S1)
            S2 = markov.dot(S2)            
        return np.sum(np.absolute(S1.transpose()[0] - S2.transpose()[0]))
        
    #Compares all documents in a given folder, outputting a matrix of their similarities
    @staticmethod
    def compareFolderDocs(folder, depth=0, quiet=False, drawMap=False, count=False):
    	doclist = [];
	allBody = [];
    	allDocs = listdir(folder)
	N = len(allDocs)
	allDist = np.zeros([N,N])
	allBody = " "
	for i in range(N):
            iFile = open(folder+"/"+allDocs[i],"r")
            iBody = iFile.read()
            doclist.append(Document(body=iBody,title=file))
            allBody = allBody+" "+iBody
        markovDoc = Document(body=allBody)
        markovMap = WordMap.generateWordMap(markovDoc, quiet)
        if (drawMap):
            plt.plot(nx.draw_networkx(markovMap,show_labels=1))
            plt.show()
        markov = WordMap.generateMarkov(markovMap)
        for i in range(N):
            for j in range(i+1,N):
               	docivec = WordMap.generateDocumentVector(markovDoc, doclist[i], count)
               	docjvec = WordMap.generateDocumentVector(markovDoc, doclist[j], count)
               	docivec /= np.sum(docivec)
               	docjvec /= np.sum(docjvec)
               	S1 = markov.dot(docivec)
               	S2 = markov.dot(docjvec)
               	for k in range(int(depth)):
                    S1 = markov.dot(S1)
                    S2 = markov.dot(S2)            
                allDist[i,j] = np.sum(np.absolute(S1.transpose()[0] - S2.transpose()[0]))
                allDist[j,i] = allDist[i,j]
	return allDist
